{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "generate_text_with_RNN_TF.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kieranfmaguire/learningdeeplearning/blob/main/notebooks/generate_text_with_RNN_TF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9ABIixKMVUG"
      },
      "source": [
        "# Generating Shakespearean Text Using a Character RNN\n",
        "---\n",
        "Based on example in chapter 16 - Hands on Machine Learnings with Scikitlearn and Tensorflow (O'Reilly)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BL_vOkc1MVUI"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvmcQrl0MVUL"
      },
      "source": [
        "## Downloading some data\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ls11I8KLMVUM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e761b01-d811-4249-8d82-dba2cc8855d3"
      },
      "source": [
        "shakespeare_url = \"https://homl.info/shakespeare\"\n",
        "filepath = tf.keras.utils.get_file(\"shakespear.txt\", shakespeare_url)\n",
        "with open(filepath) as f:\n",
        "    shakespeare_text = f.read()\n",
        "\n",
        "print(f\"shakespeare_text is a: {type(shakespeare_text)}\")\n",
        "print(f\"shakespeare_text has length: {len(shakespeare_text)}\")\n",
        "print(f\"First 500 characters are:\\n\\n{shakespeare_text[:500]}\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://homl.info/shakespeare\n",
            "1122304/1115394 [==============================] - 0s 0us/step\n",
            "shakespeare_text is a: <class 'str'>\n",
            "shakespeare_text has length: 1115394\n",
            "First 500 characters are:\n",
            "\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOp_WFo4MVUX"
      },
      "source": [
        "## Tokenizing the text data - each unique character is given a unique ID\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf3KuIZvMVUX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54d94be6-1064-4bfe-c4d6-93386b3fbec4"
      },
      "source": [
        "tokeniser = tf.keras.preprocessing.text.Tokenizer(char_level=True)   # char level creates unique id for each charater (default is by word)\n",
        "tokeniser.fit_on_texts(shakespeare_text)  # assigns ID (starting at 1) for each unique character\n",
        "num_unique_chars = len(tokeniser.word_index)\n",
        "num_chars = tokeniser.document_count    # will need this later for one hot encoding\n",
        "\n",
        "print(f\"Number of distinct characters: {len(tokeniser.word_index)}\")\n",
        "print(f\"Total number of characters in documents: {num_chars}\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of distinct characters: 39\n",
            "Total number of characters in documents: 1115394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLXG1rqbMVUX"
      },
      "source": [
        "# now encode the entire text, split into train and test, and create tf.data.Dataset object\n",
        "encoded = np.array(tokeniser.texts_to_sequences([shakespeare_text])).flatten()\n",
        "\n",
        "train_size = int(encoded.shape[0] * 0.2)    # use 20% for train\n",
        "test_size = int(encoded.shape[0] * 0.2)     # use 20% for test (help with early stopping)\n",
        "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])\n",
        "dataset_val = tf.data.Dataset.from_tensor_slices(encoded[-train_size:])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNUv0HFkMVUY"
      },
      "source": [
        "### To train the model, will use sub-sequences of length `n_steps`\n",
        "---\n",
        "the tensorflow datasets API can handle this with the window method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUdkRgLxMVUY"
      },
      "source": [
        "n_steps = 100                   # number of characters in a given instance\n",
        "window_length = n_steps + 1     # we will predict the next character in the sequence, so will need it as the target\n",
        "batch_size = 32                 # batch size for gradient descent"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ3Gps2oMVUY"
      },
      "source": [
        "dataset = dataset.window(size=window_length, shift=1, stride=1, drop_remainder=True)\n",
        "dataset = dataset.flat_map(lambda window: window.batch(window_length))\n",
        "\n",
        "dataset_val = dataset_val.window(size=window_length, shift=1, stride=1, drop_remainder=True)\n",
        "dataset_val = dataset_val.flat_map(lambda window: window.batch(window_length))\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsjU_5S-MVUY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d49adfe-ed63-4b8f-a6b8-088665ac1b1f"
      },
      "source": [
        "# have a look at the structure\n",
        "for i, dat in enumerate(dataset):\n",
        "    print(dat)\n",
        "    if i > 0: break"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[20  6  9  8  3  1 19  6  3  6 36  2 10 24 11 22  2 20  4  9  2  1 17  2\n",
            "  1 23  9  4 19  2  2 13  1  5 10 16  1 20 14  9  3  7  2  9 18  1  7  2\n",
            "  5  9  1 15  2  1  8 23  2  5 25 27 11 11  5 12 12 24 11  8 23  2  5 25\n",
            " 18  1  8 23  2  5 25 27 11 11 20  6  9  8  3  1 19  6  3  6 36  2 10 24\n",
            " 11 16  4 14  1], shape=(101,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[ 6  9  8  3  1 19  6  3  6 36  2 10 24 11 22  2 20  4  9  2  1 17  2  1\n",
            " 23  9  4 19  2  2 13  1  5 10 16  1 20 14  9  3  7  2  9 18  1  7  2  5\n",
            "  9  1 15  2  1  8 23  2  5 25 27 11 11  5 12 12 24 11  8 23  2  5 25 18\n",
            "  1  8 23  2  5 25 27 11 11 20  6  9  8  3  1 19  6  3  6 36  2 10 24 11\n",
            " 16  4 14  1  5], shape=(101,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5X5oC2XgMVUZ"
      },
      "source": [
        "# shuffle, batch, then split into fetaures and target\n",
        "dataset = dataset.shuffle(int(1e3)).batch(batch_size)\n",
        "dataset = dataset.map(lambda x: (x[:, :-1], x[:, 1:]))   \n",
        "# one hot encode the categorical features - small enough dictionary for this to be reasonable. \n",
        "# in general this would usually be an embedding\n",
        "dataset = dataset.map(lambda x, y: (tf.one_hot(x, depth=num_unique_chars), y))\n",
        "dataset = dataset.prefetch(1) # don't really need to worry about prefetching on this small dataset\n",
        "\n",
        "dataset_val = dataset_val.batch(batch_size)\\\n",
        "  .map(lambda x: (x[:, :-1], x[:, 1:]))\\\n",
        "  .map(lambda x,y: (tf.one_hot(x, depth=num_unique_chars), y))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcVPNuMbTWqt",
        "outputId": "ccb0af81-376e-46b6-dbc7-a1f58e3105ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for x,y in dataset.take(1):\n",
        "  print(x)\n",
        "  print(y)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 1. ... 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 1. 0. ... 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 1. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 1. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0. 1. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 1. ... 0. 0. 0.]]\n",
            "\n",
            " [[0. 1. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 1. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]\n",
            "  [0. 0. 0. ... 0. 0. 0.]]], shape=(32, 100, 39), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[20  6  9 ...  9  2  1]\n",
            " [ 3 27 11 ...  4  1 15]\n",
            " [ 8  1 17 ...  1  3  7]\n",
            " ...\n",
            " [21 14  2 ...  7  2  1]\n",
            " [ 4 14  9 ...  1 12  2]\n",
            " [11 11  5 ...  4 12 26]], shape=(32, 100), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiqDzM1uMVUZ"
      },
      "source": [
        "## Now we can create a model\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS0br1wyMVUZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d6672c0-7471-4fd7-9638-e871acf78864"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.GRU(units=128, input_shape=[None, num_unique_chars], return_sequences=True, dropout=0.2, recurrent_dropout=0.2),\n",
        "  tf.keras.layers.GRU(units=128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2),\n",
        "  tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(units=num_unique_chars, activation=\"softmax\"))\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", \n",
        "              optimizer=\"adam\", \n",
        "              metrics=['sparse_categorical_crossentropy']\n",
        "              )\n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer gru_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_2 (GRU)                  (None, None, 128)         64896     \n",
            "_________________________________________________________________\n",
            "gru_3 (GRU)                  (None, None, 128)         99072     \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, None, 39)          5031      \n",
            "=================================================================\n",
            "Total params: 168,999\n",
            "Trainable params: 168,999\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqsPqUieduTg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccdb8146-2261-4126-de80-8e26bca1edce"
      },
      "source": [
        "history = model.fit(dataset, epochs=4, validation_data=dataset_val, callbacks=[tf.keras.callbacks.EarlyStopping(patience=1)], verbose=2)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "6969/6969 - 4316s - loss: 1.6142 - sparse_categorical_crossentropy: 1.6142 - val_loss: 2.1134 - val_sparse_categorical_crossentropy: 2.1134\n",
            "Epoch 2/4\n",
            "6969/6969 - 4198s - loss: 1.4270 - sparse_categorical_crossentropy: 1.4270 - val_loss: 2.0876 - val_sparse_categorical_crossentropy: 2.0876\n",
            "Epoch 3/4\n",
            "6969/6969 - 4373s - loss: 1.3829 - sparse_categorical_crossentropy: 1.3829 - val_loss: 2.0652 - val_sparse_categorical_crossentropy: 2.0652\n",
            "Epoch 4/4\n",
            "6969/6969 - 4112s - loss: 1.3605 - sparse_categorical_crossentropy: 1.3605 - val_loss: 2.0590 - val_sparse_categorical_crossentropy: 2.0590\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4zmg95p3icQ",
        "outputId": "19c47af1-dae8-4c9e-9a39-9b7369edec42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f8a3066c7f0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRMslTfvWAgU"
      },
      "source": [
        "## Create some utility functions to help generate text\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdELFp-tV6Zc"
      },
      "source": [
        "def preprocess(text):\n",
        "  return tf.one_hot(np.array(tokeniser.texts_to_sequences([text])), depth=num_unique_chars)\n",
        "\n",
        "def next_char(text):\n",
        "  processed = preprocess(text)\n",
        "  return tf.math.argmax(model.predict(processed), axis=-1)[:,-1:]\n",
        "\n",
        "def next_char_rand(text, temp):\n",
        "  processed = preprocess(text)\n",
        "  probs = model.predict(processed)[0,-1:,:]\n",
        "  log_probs_rescaled = tf.math.log(probs) / temp\n",
        "  return tf.random.categorical(log_probs_rescaled, 1)\n",
        "\n",
        "def decode(encoded):\n",
        "  return tokeniser.sequences_to_texts(encoded.numpy())\n",
        "\n",
        "def generate_text(starting_text, n, temp):\n",
        "  text = starting_text\n",
        "  for _ in range(n):\n",
        "    new_char = decode(next_char_rand(text, temp))[0]\n",
        "    text += new_char\n",
        "  return text"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wm6qDegJYFpP",
        "outputId": "987871f3-c51f-4df1-f16e-3e357f2e116e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "new_txt = generate_text('hello', 100, 0.5)\n",
        "print(new_txt)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hellows and made the way\n",
            "the cousin, my son of your gracious\n",
            "and faith of your cousin, i'll go welcome,\n",
            "t\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}