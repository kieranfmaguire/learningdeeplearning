{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "generate_text_with_RNN_TF.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9ABIixKMVUG"
      },
      "source": [
        "# Generating Shakespearean Text Using a Character RNN\n",
        "---\n",
        "Based on example in chapter 16 - Hands on Machine Learnings with Scikitlearn and Tensorflow (O'Reilly)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BL_vOkc1MVUI"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvmcQrl0MVUL"
      },
      "source": [
        "## Downloading some data\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ls11I8KLMVUM",
        "outputId": "de214878-48f9-4fc7-9caf-3213da5da332",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "shakespeare_url = \"https://homl.info/shakespeare\"\n",
        "filepath = tf.keras.utils.get_file(\"shakespear.txt\", shakespeare_url)\n",
        "with open(filepath) as f:\n",
        "    shakespeare_text = f.read()\n",
        "\n",
        "print(f\"shakespeare_text is a: {type(shakespeare_text)}\")\n",
        "print(f\"shakespeare_text has length: {len(shakespeare_text)}\")\n",
        "print(f\"First 500 characters are:\\n\\n{shakespeare_text[:500]}\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shakespeare_text is a: <class 'str'>\n",
            "shakespeare_text has length: 1115394\n",
            "First 500 characters are:\n",
            "\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOp_WFo4MVUX"
      },
      "source": [
        "## Tokenizing the text data - each unique character is given a unique ID\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf3KuIZvMVUX",
        "outputId": "c2d48281-05bb-4aa3-8d75-425357bca6b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokeniser = tf.keras.preprocessing.text.Tokenizer(char_level=True)   # char level creates unique id for each charater (default is by word)\n",
        "tokeniser.fit_on_texts(shakespeare_text)  # assigns ID (starting at 1) for each unique character\n",
        "num_unique_chars = len(tokeniser.word_index)\n",
        "num_chars = tokeniser.document_count    # will need this later for one hot encoding\n",
        "\n",
        "print(f\"Number of distinct characters: {len(tokeniser.word_index)}\")\n",
        "print(f\"Total number of characters in documents: {num_chars}\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of distinct characters: 39\n",
            "Total number of characters in documents: 1115394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLXG1rqbMVUX"
      },
      "source": [
        "# now encode the entire text, split into train and test, and create tf.data.Dataset object\n",
        "encoded = np.array(tokeniser.texts_to_sequences([shakespeare_text])).flatten()\n",
        "\n",
        "train_size = int(encoded.shape[0] * 0.9)    # use 90% for train, save the rest for test\n",
        "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNUv0HFkMVUY"
      },
      "source": [
        "### To train the model, will use sub-sequences of length `n_steps`\n",
        "---\n",
        "the tensorflow datasets API can handle this with the window method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUdkRgLxMVUY"
      },
      "source": [
        "n_steps = 50                    # number of characters in a given instance\n",
        "window_length = n_steps + 1     # we will predict the next character in the sequence, so will need it as the target\n",
        "batch_size = 32                 # batch size for gradient descent"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ3Gps2oMVUY"
      },
      "source": [
        "dataset = dataset.window(size=window_length, shift=1, stride=1, drop_remainder=False)\n",
        "dataset = dataset.flat_map(lambda window: window.batch(window_length))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsjU_5S-MVUY",
        "outputId": "dea1f1b7-1a64-48bc-8122-561c422745f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# have a look at the structure\n",
        "for i, dat in enumerate(dataset):\n",
        "    print(dat)\n",
        "    if i > 0: break"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[20  6  9  8  3  1 19  6  3  6 36  2 10 24 11 22  2 20  4  9  2  1 17  2\n",
            "  1 23  9  4 19  2  2 13  1  5 10 16  1 20 14  9  3  7  2  9 18  1  7  2\n",
            "  5  9  1], shape=(51,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[ 6  9  8  3  1 19  6  3  6 36  2 10 24 11 22  2 20  4  9  2  1 17  2  1\n",
            " 23  9  4 19  2  2 13  1  5 10 16  1 20 14  9  3  7  2  9 18  1  7  2  5\n",
            "  9  1 15], shape=(51,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5X5oC2XgMVUZ"
      },
      "source": [
        "# shuffle, batch, then split into fetaures and target\n",
        "dataset = dataset.shuffle(int(1e3)).batch(batch_size)\n",
        "dataset = dataset.map(lambda x: (x[:, :-1], x[:, 1:]))   \n",
        "# one hot encode the categorical features - small enough dictionary for this to be reasonable. \n",
        "# in general this would usually be an embedding\n",
        "dataset = dataset.map(lambda x, y: (tf.one_hot(x, depth=num_unique_chars), y))\n",
        "dataset = dataset.prefetch(1) # don't really need to worry about prefetching on this small dataset"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiqDzM1uMVUZ"
      },
      "source": [
        "## Now we can create a model\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS0br1wyMVUZ",
        "outputId": "debd54ba-602c-40dc-df2f-3355b260752b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.GRU(units=64, input_shape=[None, num_unique_chars], return_sequences=True, dropout=0.2, recurrent_dropout=0.2),\n",
        "  tf.keras.layers.GRU(units=64, return_sequences=True, dropout=0.2, recurrent_dropout=0.2),\n",
        "  tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(units=num_unique_chars, activation=\"softmax\"))\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
        "model.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_2 (GRU)                  (None, None, 64)          20160     \n",
            "_________________________________________________________________\n",
            "gru_3 (GRU)                  (None, None, 64)          24960     \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, None, 39)          2535      \n",
            "=================================================================\n",
            "Total params: 47,655\n",
            "Trainable params: 47,655\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}