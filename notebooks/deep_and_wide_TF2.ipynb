{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# California housing dataset with Functional API\n",
    "---\n",
    "\n",
    "Try a regression problem, using the functional API which is more flexible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "tf.__version__\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "---\n",
    "\n",
    "Note pytorch also has an API for loading and downloading datasets, but keras version used below is more explicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "x_train_full, x_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train_full, y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit(x_train).transform(x_train)\n",
    "x_valid, x_test = scaler.transform(x_valid), scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep and wide model\n",
    "---\n",
    "A deep and wide model connects some or all of the inputs directly to output layer, as well as pass through deeper layers. This kind of model cannot be specified using just the sequential API\n",
    "\n",
    "The semantics is similar, but all layers can be thought of as functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 30)           270         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 30)           930         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 38)           0           input_1[0][0]                    \n",
      "                                                                 dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            39          concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define how the data flows through the model\n",
    "input_ = keras.layers.Input(shape=x_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(units=30, activation='relu')(input_)\n",
    "hidden2 = keras.layers.Dense(units=30, activation='relu')(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(units=1)(concat)\n",
    "\n",
    "# wrap in keras.Model\n",
    "model = keras.Model(inputs=[input_], outputs=[output])\n",
    "\n",
    "# compile as usual\n",
    "model.compile(loss=keras.losses.MSE, optimizer=keras.optimizers.SGD(lr=1e-3), metrics=['mae'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "182/182 [==============================] - 5s 26ms/step - loss: 2.0755 - mae: 1.0201 - val_loss: 1.0108 - val_mae: 0.7417\n",
      "Epoch 2/10\n",
      "182/182 [==============================] - 5s 26ms/step - loss: 0.8191 - mae: 0.6581 - val_loss: 0.7539 - val_mae: 0.6319\n",
      "Epoch 3/10\n",
      "182/182 [==============================] - 4s 22ms/step - loss: 0.7048 - mae: 0.6080 - val_loss: 0.7068 - val_mae: 0.6065\n",
      "Epoch 4/10\n",
      "182/182 [==============================] - 3s 18ms/step - loss: 0.6677 - mae: 0.5885 - val_loss: 0.6765 - val_mae: 0.5905\n",
      "Epoch 5/10\n",
      "182/182 [==============================] - 3s 17ms/step - loss: 0.6395 - mae: 0.5733 - val_loss: 0.6511 - val_mae: 0.5807\n",
      "Epoch 6/10\n",
      "182/182 [==============================] - 4s 22ms/step - loss: 0.6164 - mae: 0.5640 - val_loss: 0.6322 - val_mae: 0.5688\n",
      "Epoch 7/10\n",
      "182/182 [==============================] - 3s 17ms/step - loss: 0.5966 - mae: 0.5531 - val_loss: 0.6131 - val_mae: 0.5617\n",
      "Epoch 8/10\n",
      "182/182 [==============================] - 3s 17ms/step - loss: 0.5789 - mae: 0.5455 - val_loss: 0.5989 - val_mae: 0.5531\n",
      "Epoch 9/10\n",
      "182/182 [==============================] - 3s 17ms/step - loss: 0.5634 - mae: 0.5379 - val_loss: 0.5853 - val_mae: 0.5464\n",
      "Epoch 10/10\n",
      "182/182 [==============================] - 4s 21ms/step - loss: 0.5503 - mae: 0.5314 - val_loss: 0.5727 - val_mae: 0.5407\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=64, epochs=10, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same model but specify which inputs get sent directly to ouput layer, and whic inputs pass through the model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ndeep_input (InputLayer)         [(None, 6)]          0                                            \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 30)           210         deep_input[0][0]                 \n__________________________________________________________________________________________________\nwide_input (InputLayer)         [(None, 5)]          0                                            \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 30)           930         dense[0][0]                      \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (None, 35)           0           wide_input[0][0]                 \n                                                                 dense_1[0][0]                    \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 1)            36          concatenate[0][0]                \n==================================================================================================\nTotal params: 1,176\nTrainable params: 1,176\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define the two input sizes\n",
    "input_dim_1 = 5\n",
    "input_dim_2 = 6\n",
    "\n",
    "# define how the data flows through the model\n",
    "input_1 = keras.layers.Input(shape=input_dim_1, name=\"wide_input\")\n",
    "input_2 = keras.layers.Input(shape=input_dim_2, name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(units=30, activation='relu')(input_2)\n",
    "hidden2 = keras.layers.Dense(units=30, activation='relu')(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_1, hidden2])\n",
    "output = keras.layers.Dense(units=1)(concat)\n",
    "\n",
    "# wrap in keras.Model\n",
    "model = keras.Model(inputs=[input_1, input_2], outputs=[output])\n",
    "\n",
    "# compile as usual\n",
    "model.compile(loss=keras.losses.MSE, optimizer=keras.optimizers.SGD(lr=1e-3), metrics=['mae'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "182/182 [==============================] - 7s 36ms/step - loss: 3.2643 - mae: 1.4133 - val_loss: 1.4259 - val_mae: 0.8663\n",
      "Epoch 2/10\n",
      "182/182 [==============================] - 6s 33ms/step - loss: 1.1049 - mae: 0.7701 - val_loss: 0.8914 - val_mae: 0.7038\n",
      "Epoch 3/10\n",
      "182/182 [==============================] - 5s 26ms/step - loss: 0.8614 - mae: 0.6951 - val_loss: 0.7772 - val_mae: 0.6623\n",
      "Epoch 4/10\n",
      "182/182 [==============================] - 5s 27ms/step - loss: 0.7757 - mae: 0.6620 - val_loss: 0.7217 - val_mae: 0.6367\n",
      "Epoch 5/10\n",
      "182/182 [==============================] - 6s 31ms/step - loss: 0.7275 - mae: 0.6395 - val_loss: 0.6885 - val_mae: 0.6191\n",
      "Epoch 6/10\n",
      "182/182 [==============================] - 6s 32ms/step - loss: 0.6961 - mae: 0.6238 - val_loss: 0.6667 - val_mae: 0.6069\n",
      "Epoch 7/10\n",
      "182/182 [==============================] - 5s 26ms/step - loss: 0.6736 - mae: 0.6125 - val_loss: 0.6504 - val_mae: 0.5969\n",
      "Epoch 8/10\n",
      "182/182 [==============================] - 5s 28ms/step - loss: 0.6560 - mae: 0.6035 - val_loss: 0.6366 - val_mae: 0.5874\n",
      "Epoch 9/10\n",
      "182/182 [==============================] - 4s 23ms/step - loss: 0.6413 - mae: 0.5942 - val_loss: 0.6251 - val_mae: 0.5833\n",
      "Epoch 10/10\n",
      "182/182 [==============================] - 5s 25ms/step - loss: 0.6286 - mae: 0.5892 - val_loss: 0.6143 - val_mae: 0.5747\n"
     ]
    }
   ],
   "source": [
    "# set up the data splits\n",
    "x_train_1, x_valid_1 = x_train[:,:input_dim_1], x_valid[:,:input_dim_1]\n",
    "x_train_2, x_valid_2 = x_train[:,-input_dim_2:], x_valid[:,-input_dim_2:]\n",
    "\n",
    "# train the model\n",
    "history = model.fit(x=(x_train_1, x_train_2), y=y_train, batch_size=64, epochs=10, validation_data=((x_valid_1, x_valid_2), y_valid))"
   ]
  },
  {
   "source": [
    "## Subclassing API to build dynamic behaviour nets\n",
    "---\n",
    "Key points:\n",
    "\n",
    "1. Subclass on `keras.Model`\n",
    "2. Define any layers needed inside the constructor\n",
    "3. Define how inputs flow through the model (including any dynamic behaviour) inside the call method\n",
    "\n",
    "*Example* The below specifies a network similare to above, except that data is passed through the second hidden layer a random number of times between 1 and 3\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomNet(keras.Model):\n",
    "    def __init__(self, units=30, activation='relu', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        input_wide, input_deep = inputs  # inputs should be provides as tuple, just unpack it here\n",
    "        input_deep = self.hidden1(input_deep)\n",
    "        for _ in range(np.random.randint(3)):\n",
    "            input_deep = self.hidden2(input_deep)\n",
    "        concat = keras.layers.concatenate([input_wide, input_deep])\n",
    "        output_aux = self.aux_output(input_deep)\n",
    "        output_main = self.main_output(concat)\n",
    "        return output_main, output_aux\n",
    "\n",
    "model = RandomNet()\n",
    "model.compile(loss=[keras.losses.MSE, keras.losses.MSE], optimizer=keras.optimizers.SGD(lr=1e-3), metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "182/182 [==============================] - 9s 47ms/step - loss: 6.5541 - output_1_loss: 3.1122 - output_2_loss: 3.4419 - output_1_mae: 1.3579 - output_2_mae: 1.4607 - val_loss: 11.9420 - val_output_1_loss: 5.4344 - val_output_2_loss: 6.5076 - val_output_1_mae: 0.8490 - val_output_2_mae: 0.9474\n",
      "Epoch 2/10\n",
      "182/182 [==============================] - 7s 39ms/step - loss: 2.4909 - output_1_loss: 1.1108 - output_2_loss: 1.3801 - output_1_mae: 0.7421 - output_2_mae: 0.8648 - val_loss: 6.8714 - val_output_1_loss: 2.9154 - val_output_2_loss: 3.9560 - val_output_1_mae: 0.6661 - val_output_2_mae: 0.8215\n",
      "Epoch 3/10\n",
      "182/182 [==============================] - 8s 45ms/step - loss: 1.8915 - output_1_loss: 0.7733 - output_2_loss: 1.1182 - output_1_mae: 0.6522 - output_2_mae: 0.8126 - val_loss: 5.8154 - val_output_1_loss: 2.3608 - val_output_2_loss: 3.4546 - val_output_1_mae: 0.6238 - val_output_2_mae: 0.7971\n",
      "Epoch 4/10\n",
      "182/182 [==============================] - 7s 38ms/step - loss: 1.7173 - output_1_loss: 0.6887 - output_2_loss: 1.0286 - output_1_mae: 0.6168 - output_2_mae: 0.7828 - val_loss: 5.3744 - val_output_1_loss: 2.1655 - val_output_2_loss: 3.2089 - val_output_1_mae: 0.6016 - val_output_2_mae: 0.7697\n",
      "Epoch 5/10\n",
      "182/182 [==============================] - 7s 38ms/step - loss: 1.6086 - output_1_loss: 0.6492 - output_2_loss: 0.9595 - output_1_mae: 0.5965 - output_2_mae: 0.7530 - val_loss: 5.0211 - val_output_1_loss: 2.0500 - val_output_2_loss: 2.9710 - val_output_1_mae: 0.5900 - val_output_2_mae: 0.7486\n",
      "Epoch 6/10\n",
      "182/182 [==============================] - 7s 40ms/step - loss: 1.5271 - output_1_loss: 0.6249 - output_2_loss: 0.9022 - output_1_mae: 0.5837 - output_2_mae: 0.7284 - val_loss: 4.8481 - val_output_1_loss: 1.9987 - val_output_2_loss: 2.8493 - val_output_1_mae: 0.5776 - val_output_2_mae: 0.7250\n",
      "Epoch 7/10\n",
      "182/182 [==============================] - 7s 39ms/step - loss: 1.4634 - output_1_loss: 0.6065 - output_2_loss: 0.8569 - output_1_mae: 0.5744 - output_2_mae: 0.7079 - val_loss: 4.7609 - val_output_1_loss: 1.9759 - val_output_2_loss: 2.7851 - val_output_1_mae: 0.5664 - val_output_2_mae: 0.7036\n",
      "Epoch 8/10\n",
      "182/182 [==============================] - 6s 36ms/step - loss: 1.4152 - output_1_loss: 0.5930 - output_2_loss: 0.8221 - output_1_mae: 0.5663 - output_2_mae: 0.6906 - val_loss: 4.5967 - val_output_1_loss: 1.9329 - val_output_2_loss: 2.6638 - val_output_1_mae: 0.5610 - val_output_2_mae: 0.6917\n",
      "Epoch 9/10\n",
      "182/182 [==============================] - 6s 36ms/step - loss: 1.3770 - output_1_loss: 0.5813 - output_2_loss: 0.7957 - output_1_mae: 0.5598 - output_2_mae: 0.6779 - val_loss: 4.4825 - val_output_1_loss: 1.8983 - val_output_2_loss: 2.5841 - val_output_1_mae: 0.5556 - val_output_2_mae: 0.6819\n",
      "Epoch 10/10\n",
      "182/182 [==============================] - 7s 40ms/step - loss: 1.3470 - output_1_loss: 0.5713 - output_2_loss: 0.7757 - output_1_mae: 0.5542 - output_2_mae: 0.6678 - val_loss: 4.3776 - val_output_1_loss: 1.8598 - val_output_2_loss: 2.5178 - val_output_1_mae: 0.5520 - val_output_2_mae: 0.6745\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fae901e0bb0>"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "model.fit(x=(x_train_1, x_train_2), y=(y_train, y_train), batch_size=64, epochs=10, validation_data=((x_valid_1, x_valid_2), y_valid, y_valid))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}